{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"master02.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"id":"p8QlnapPGhr5","colab_type":"code","outputId":"924bc752-1d6a-4d09-feef-2c83ed3814f5","executionInfo":{"status":"ok","timestamp":1587177199289,"user_tz":240,"elapsed":947,"user":{"displayName":"Sharjeel Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhoSEBjaUf22Pi5vqd8e5QH7qmHdmAencDu5CUtDQ=s64","userId":"00857062592148981405"}},"colab":{"base_uri":"https://localhost:8080/","height":245}},"source":["\n","## Census data ##\n","\n","\n","#imports\n","import numpy as np\n","from matplotlib import pyplot as plt\n","from sklearn.mixture import GaussianMixture\n","from sklearn.decomposition import PCA\n","from sklearn.linear_model import LinearRegression\n","from sklearn.linear_model import Ridge\n","from sklearn.linear_model import Lasso\n","from sklearn.cluster import DBSCAN\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_selection import SelectKBest, chi2\n","from sklearn.preprocessing import PolynomialFeatures\n","import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import LabelEncoder\n","\n","# workclass, education, relationship, sex\n","\n","# Define the headers since the data does not have any\n","headers = [\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\", \"marital status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"native-country\", \"income\"]\n","headers2 = [\"age\", \"workclass\", \"education\", \"education-num\", \"marital status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"native-country\", \"income\"]\n","\n","# Read in the CSV file and convert \"?\" to NaN\n","#df = pd.read_csv('/content/sample_data/census_data.txt', header=None, names=headers, na_values=\"?\" )\n","df = pd.read_csv('/content/sample_data/adjusted_data.csv', header=0, names=headers2, na_values=\"?\" )\n","\n","print(\"Shape of dataframe \",df.shape)\n","df = df[~(df == \" ?\").any(axis=1)]\n","#df = df[~(df2 == \" ?\").any(axis=1)]\n","print(\"Shape of the dataframe after getting rid of ? \" , df.shape)\n","\n","# drop fnlwgt\n","#df = df.drop(\"fnlwgt\",axis = 1)\n","#Change this to drop it from dataframe and to make it the label\n","label_name = \"education\"                                                                # EDIT LABEL HERE\n","label_df = df[label_name].copy()\n","df = df.drop([label_name],axis= 1)\n","\n","dummy_labels = pd.get_dummies(label_df.copy())\n","unique_df = dummy_labels.columns.values\n","dummy_labels = dummy_labels.to_numpy()\n","\n","lb_label = LabelEncoder()\n","label_df[\"label_code\"] = lb_label.fit_transform(label_df)\n","\n","\n","print(\"shape of dataframe after dropping label \",df.shape)\n","print(\"shape of the labels \",label_df.shape)\n","\n","#print(df.dtypes)\n","int_df = df.select_dtypes(include =[\"int64\"]).copy()\n","obj_df = df.select_dtypes(include=['object']).copy()\n","#print(obj_df.shape)\n","#print(int_df.shape)\n","new_obj_df = pd.get_dummies(obj_df)\n","#print(new_obj_df)\n","\n","print(\"this is the shape of the continuous data \", int_df.shape)\n","print(\"This is the shape of the object data \", obj_df.shape)\n","\n","frames = [int_df, new_obj_df]\n","result = pd.concat(frames, axis= 1)\n","print(\"shape of dataframe adding the extra columns with get dummies \", result.shape)\n","#print(result)\n","#occupation\n","\n","data = result.to_numpy()\n","int_data = int_df.to_numpy()\n","encoded_labels = label_df[\"label_code\"]\n","\n","print(\"shape after converting dataframe to np \",data.shape)\n","print(\"shape of encoded labels \", encoded_labels.shape)\n","#print(labels.shape)\n","\n","\n","scaler_X = StandardScaler()\n","data = scaler_X.fit_transform(data)\n","print(\"shape of data after being scaled \", data.shape)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Shape of dataframe  (32517, 14)\n","Shape of the dataframe after getting rid of ?  (32517, 14)\n","shape of dataframe after dropping label  (32517, 13)\n","shape of the labels  (32518,)\n","this is the shape of the continuous data  (32517, 5)\n","This is the shape of the object data  (32517, 8)\n","shape of dataframe adding the extra columns with get dummies  (32517, 100)\n","shape after converting dataframe to np  (32517, 100)\n","shape of encoded labels  (32517,)\n","shape of data after being scaled  (32517, 100)\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/pandas/core/ops/array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n","  res_values = method(rvalues)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"NsH3M3WTGhtA","colab_type":"code","outputId":"b29a909e-f750-4576-e1b6-3b616a6cc473","executionInfo":{"status":"error","timestamp":1587177203335,"user_tz":240,"elapsed":801,"user":{"displayName":"Sharjeel Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhoSEBjaUf22Pi5vqd8e5QH7qmHdmAencDu5CUtDQ=s64","userId":"00857062592148981405"}},"colab":{"base_uri":"https://localhost:8080/","height":271}},"source":["######## DECISION TREE + RANDOM FOREST STUFF #########\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, plot_confusion_matrix\n","from sklearn.metrics import roc_auc_score\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.linear_model import LinearRegression\n","from sklearn.model_selection import train_test_split\n","from sklearn.svm import SVC \n","import pandas as pd\n","from sklearn.preprocessing import LabelEncoder\n","\n","# General overview of variance (calculated in PCA)\n","#cont_data = cont_data - np.mean(cont_data, axis=0)\n","\n","#Accuracy Lists                          \n","decisiontree_list = []\n","randomforest_list = []\n","svm_list = []\n","linear_list=[]\n","ridge_list = []\n","lasso_list = []\n","\n","\n","x_vals = [1, 2, 4, 8, 10, 15, 20, 25, 30]                                   #--------- choose PCA of 8 for hypertuning/final plots\n","for i in x_vals:\n","  pca_overall = PCA(n_components = i)\n","  pca_data = pca_overall.fit_transform(data)\n","\n","  extracted_data = pca_data\n","  extracted_labels = encoded_labels\n","\n","  X_train, X_test, y_train, y_test = train_test_split(extracted_data, extracted_labels, test_size=0.3,random_state=109) # 70% training and 30% test\n","\n","  print(\"shape of the pca data \",pca_data.shape)\n","  classifier = DecisionTreeClassifier(max_depth=10, min_sample_split=0.0001)                                 ## Pooja's Hypertuned Parameters: max_depth = 10, min_sample_splits=0.0001\n","  classifier.fit(X_train, y_train)\n","  y_pred = classifier.predict(X_test)\n","  decisiontree_list.append(classifier.score(X_test, y_test) * 100)\n","\n","\n","  clf = RandomForestClassifier(n_estimators = 100, max_depth=10, n_jobs = -1)                                  ## Aakash's Hypertuned Parameters: n_estimators = 100, max_depth=10\n","  clf.fit(X_train, y_train)\n","  y_pred = clf.predict(X_test)\n","\n","  randomforest_list.append(clf.score(X_test, y_test) * 100)\n","\n","  svm_model_linear = SVC(kernel = 'poly', C = 1, gamma = 0.054).fit(X_train, y_train)                         ## Josh's Hypertuned Parameters: C = 1, gamma = 0.054\n","  svm_predictions = svm_model_linear.predict(X_test) \n","  y_pred = svm_predictions\n","  svm_list.append(svm_model_linear.score(X_test, y_test) * 100)\n","  print(\"This is the accuracy of the classifier: \", svm_model_linear.score(X_test, y_test))\n","\n","for j in x_vals:\n","  pca_overall = PCA(n_components = j)\n","  pca_data = pca_overall.fit_transform(data)\n","\n","  extracted_data = pca_data\n","  #poly = PolynomialFeatures(degree=4)\n","  extracted_data = poly.fit_transform(extracted_data)\n","  X_train, X_test, y_train, y_test = train_test_split(extracted_data, dummy_labels, test_size=0.3,random_state=109)\n","  ridge_dummy = np.ones((X_test.shape[0], unique_df.shape[0]))\n","  lasso_dummy = np.ones((X_test.shape[0], unique_df.shape[0]))\n","  linear_dummy = np.ones((X_test.shape[0], unique_df.shape[0]))\n","  for i in range(unique_df.shape[0]):\n","    y_train_i = y_train[:,i]\n","    linear = LinearRegression()\n","    linear.fit(X_train, y_train_i)\n","    linear_dummy[:,i] = linear.predict(X_test)\n","\n","\n","    ridge = Ridge(alpha=0.1,max_iter=2000)\n","    ridge.fit(X_train, y_train_i)\n","    ridge_dummy[:,i] = ridge.predict(X_test)\n","\n","    lasso = Lasso(alpha=0.1,max_iter=2000)\n","    lasso.fit(X_train, y_train_i)\n","    lasso_dummy[:,i] = lasso.predict(X_test)\n","  linear_dummy = np.argmax(linear_dummy, axis=1)\n","  ridge_dummy = np.argmax(ridge_dummy, axis=1)\n","  lasso_dummy = np.argmax(lasso_dummy, axis=1)\n","  y_test_max = np.argmax(y_test, axis=1)\n","  linear_list.append(accuracy_score(linear_dummy, y_test_max)*100)\n","  ridge_list.append(accuracy_score(ridge_dummy, y_test_max)*100)\n","  lasso_list.append(accuracy_score(lasso_dummy, y_test_max)*100)\n","\n","print(linear_list)\n","print(randomforest_list)\n","# print(svm_list)\n","# print(decisiontree_list)\n"],"execution_count":17,"outputs":[{"output_type":"stream","text":["shape of the pca data  (32517, 1)\n"],"name":"stdout"},{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-c88c7e090899>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"shape of the pca data \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpca_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m   \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_sample_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m                                 \u001b[0;31m## Pooja's Hypertuned Parameters: max_depth = 10, min_sample_splits=0.0001\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m   \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m   \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'min_sample_splits'"]}]},{"cell_type":"code","metadata":{"id":"BuvYFTaUZbyc","colab_type":"code","outputId":"0a2cf286-9e5e-4a7f-f291-1c2d53f12e4b","executionInfo":{"status":"error","timestamp":1587174677628,"user_tz":240,"elapsed":402,"user":{"displayName":"Joshua Fernandez","photoUrl":"","userId":"04036230221112689599"}},"colab":{"base_uri":"https://localhost:8080/","height":231}},"source":["                                                                                  # you will need to comment out the other classifiers so your y_pred is from the one of interest\n","\n","                                                                                  # if you have small numebr of labels - you can turn on the numbers within the boxes.\n","                                                                                  # check naming of things and ensure you only run PCA @ 8 with your tuned parameters!\n","                                                                                  \n","                                                                                  # Select the labels in the dictionary below\n","\n","# Plot non-normalized confusion matrix\n","string_dict = {0: ('Private','Self-emp-not-inc','Self-emp-inc','Federal-gov','Local-gov','State-gov','Without-pay', 'Never-worked', 'Private'),\n","                1: ('10th', '11th', '12th', '1st-4th', '5th-6th', '7th-8th', '9th', 'Assoc-acdm', 'Assoc-voc', 'Bachelors', 'Doctorate', 'HS-grad', 'Masters', 'Preschool', 'Prof-school', 'Some-college'),\n","                2: ('Divorced', 'Married-AF-spouse', 'Married-civ-spouse', 'Married-spouse-absent', 'Never-married', 'Separated', 'Widowed'),\n","                3: ('?', 'Adm-clerical', 'Armed-Forces', 'Craft-repair', 'Exec-managerial', 'Farming-fishing', 'Handlers-cleaners', 'Machine-op-inspct', 'Other-service', 'Priv-house-serv', 'Prof-specialty', 'Protective-serv', 'Sales', 'Tech-support', 'Transport-moving'),\n","               4:('Husband', 'Not-in-family', 'Other-relative', 'Own-child', 'Unmarried', 'Wife'),\n","               5: ('White', 'Asian-Pac-Islander', 'Amer-Indian-Eskimo', 'Other', 'Black'),\n","              6: ('Female', 'Male'),\n","              7:('Cambodia', 'Canada', 'China', 'Columbia', 'Cuba', 'Dominican-Republic', 'Ecuador', 'El-Salvador', 'England', 'France', 'Germany', 'Greece', 'Guatemala', 'Haiti', 'Honduras', 'Hong', 'Hungary', 'India', 'Iran', 'Ireland', 'Italy', 'Jamaica', 'Japan', 'Laos', 'Mexico', 'Nicaragua', 'Outlying-US', 'Peru', 'Philippines', 'Poland', 'Portugal', 'Puerto-Rico', 'Scotland', 'South', 'Taiwan', 'Thailand', 'Trinadad&Tobago', 'United-States', 'Vietnam', 'Yugoslavia')\n","              }\n","\n","class_names = sorted(string_dict[2])                                                     # Choose Correct labels that correpond with variable you are lookign at\n","\n","def plot_confusion_matrix(y_true, y_pred, classes,\n","                          normalize=False,\n","                          title=None,\n","                          cmap=plt.cm.Blues):\n","    \"\"\"\n","    This function prints and plots the confusion matrix.\n","    Normalization can be applied by setting `normalize=True`.\n","    \"\"\"\n","    if not title:\n","        if normalize:\n","            title = 'Normalized confusion matrix'\n","        else:\n","            title = 'Confusion matrix, without normalization'\n","\n","    # Compute confusion matrix\n","    cm = confusion_matrix(y_true, y_pred)\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","        print(\"Normalized confusion matrix\")\n","    else:\n","        print('Confusion matrix, without normalization')\n","\n","    print(cm)\n","\n","    fig, ax = plt.subplots()\n","    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n","    ax.figure.colorbar(im, ax=ax)\n","    # We want to show all ticks...\n","    ax.set(xticks=np.arange(cm.shape[1]),\n","           yticks=np.arange(cm.shape[0]),\n","           # ... and label them with the respective list entries\n","           xticklabels=classes, yticklabels=classes,\n","           title=title,\n","           ylabel='True label',\n","           xlabel='Predicted label')\n","\n","    # Rotate the tick labels and set their alignment.\n","    plt.setp(ax.get_xticklabels(), rotation=60, ha=\"right\",                      # you can edit the angle on the x axis if things are too far apart\n","             rotation_mode=\"anchor\")\n","\n","    # # Loop over data dimensions and create text annotations.                   # UNCOMMENT IF YOU WANT NUMBERS\n","    # fmt = '.2f' if normalize else 'd'                                           # UNCOMMENT IF YOU WANT NUMBERS\n","    # thresh = cm.max() / 2.                                                      # UNCOMMENT IF YOU WANT NUMBERS\n","    # for i in range(cm.shape[0]):                                                # UNCOMMENT IF YOU WANT NUMBERS\n","    #     for j in range(cm.shape[1]):                                            # UNCOMMENT IF YOU WANT NUMBERS\n","    #         ax.text(j, i, format(cm[i, j], fmt),\n","    #                 ha=\"center\", va=\"center\",\n","    #                 color=\"white\" if cm[i, j] > thresh else \"black\")\n","    # fig.tight_layout()\n","    return ax\n","\n","\n","np.set_printoptions(precision=2)\n","\n","# Plot non-normalized confusion matrix\n","plot_confusion_matrix(y_test, y_pred, classes=class_names,\n","                      title='Confusion matrix, without normalization')\n","\n","# Plot normalized confusion matrix\n","plot_confusion_matrix(y_test, y_pred, classes=class_names, normalize=True,\n","                      title='Normalized confusion matrix')\n","\n","plt.show()"],"execution_count":0,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-6d8d0e660d72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m                           \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                           \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                           cmap=plt.cm.Blues):\n\u001b[0m\u001b[1;32m     17\u001b[0m     \"\"\"\n\u001b[1;32m     18\u001b[0m     \u001b[0mThis\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0mprints\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mplots\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mconfusion\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"]}]},{"cell_type":"code","metadata":{"id":"LweolB10FLg1","colab_type":"code","outputId":"c605e430-ec06-4e27-ba1e-b55b7133d7fb","executionInfo":{"status":"error","timestamp":1587137106857,"user_tz":240,"elapsed":635,"user":{"displayName":"Joshua Fernandez","photoUrl":"","userId":"04036230221112689599"}},"colab":{"base_uri":"https://localhost:8080/","height":792}},"source":["\n","#OpenSSL Timing Graph\n","#colors to use, if needed\n","\n","plt.style.use('default')\n","tableau20 = [(31, 119, 180), (174, 199, 232), (255, 127, 14), (255, 187, 120),\n","                (44, 160, 44), (152, 223, 138), (214, 39, 40), (255, 152, 150),                        \n","                (148, 103, 189), (197, 176, 213), (140, 86, 75), (196, 156, 148),                      \n","                (227, 119, 194), (247, 182, 210), (127, 127, 127), (199, 199, 199),                    \n","                (188, 189, 34), (219, 219, 141), (23, 190, 207), (158, 218, 229)]                      \n","\n","'''\n","#####################################################################################################\n","# In: x_var  y_multiVar  y_varLegends ImgOutName  Title Ylabel\n","# Out: Image with bargraph comparison\n","# The function takes in \"x variables (x_var)\" and multiple y_var to be stacked \n","# and outputs an image with name ImgoutName, title Title, and ylabel Ylabel\n","##################################################################################################### \n","'''\n","class Line:\n","    id=None\n","    x_val_arr=None\n","    y_val_arr=None\n","    legend=None\n","\n","class plot:\n","    pca=None\n","    decisiontree=None\n","    randomforest=None\n","    svm=None\n","    linear=None\n","\n","def drawLines(Lines, ImgOutName, XLabel, YLabel, Title):\n","\n","    # Scale the RGB values to the [0, 1] range, which is the format matplotlib accepts.                 \n","    for i in range(len(tableau20)):\n","        r, g, b = tableau20[i]\n","        tableau20[i] = (r / 255., g / 255., b / 255.) \n","        \n","    #different hatches\n","    patterns = ('.', '+', 'x', '*', 'o', 'O', '.', '\\\\')\n","    colors = ['red', 'blue', 'green',  'orange', 'black', 'fuchsia', 'gold', 'peru']\n","    NumPatterns = len(patterns)\n","    numLines = len(Lines)\n","    plt.gca().set_prop_cycle(color=colors, marker=patterns)\n","\n","    i = 0\n","    linestyles = ['-', '--', '-.', ':']\n","    for line in Lines:\n","        linestyle = linestyles[i]\n","        plt.plot(line.x_val_arr, line.y_val_arr, label=line.legend,\n","                 linestyle=linestyle, linewidth=3)\n","        i += 1\n","\n","    #plt.legend(loc='upper left', fontsize=28)\n","    #plt.legend(loc='upper center', fontsize=28)\n","    plt.legend(loc='best', fontsize=12)\n","    plt.xticks(fontsize = 14)\n","    plt.yticks(fontsize = 14)\n","    plt.ylabel(YLabel, labelpad=6, fontsize=24)\n","    plt.xlabel(XLabel, labelpad=6, fontsize=24)\n","    plt.title(Title, fontsize=28)\n","    plt.grid(True)\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","actual_time=['Decision Tree', \"Random Forest\", \"SVM\", \"Linear Regression\"]\n","i = 0\n","plots = []\t\n","#print \" printing in hashs\"\n","for benchmark in actual_time:\n","    p = plot()\n","    p.loopid = benchmark\n","#print p.loopid\n","    p.nbna = Line()\n","    p.nbna.id = benchmark\n","    p.nbna.x_val_arr = x_vals\n","    p.nbna.y_val_arr = decisiontree_list\n","    p.nbna.legend = \"Decision Tree\"\n","#print p.actual_line.y_val_arr\n","\n","    p.bna = Line()\n","    p.bna.id = benchmark\n","    p.bna.x_val_arr = x_vals\n","    p.bna.y_val_arr = randomforest_list\n","    p.bna.legend = \"Random Forest\"\n","\n","    p.bfr = Line()\n","    p.bfr.id = benchmark\n","    p.bfr.x_val_arr = x_vals\n","    p.bfr.y_val_arr = svm_list\n","    p.bfr.legend = \"SVM\"\n","\n","    p.bff = Line()\n","    p.bff.id = benchmark\n","    p.bff.x_val_arr = x_vals\n","    p.bff.y_val_arr = linear_list\n","    p.bff.legend = \"Linear Regressionh\"\n","\n","#print p.predicted_line.y_val_arr\n","    plots.append(p)\n","\n","for p in plots:\n","    Title = \"\"\n","    drawLines([p.nbna, p.bna, p.bfr, p.bff],\"\",\n","               \"Number of Processes\",\"Accuracy\",Title)\t\n","    # drawLines([p.nbna, p.nbfr, p.nbpp, p.npff, p.bna, p.bfr, p.bff, p.bpp],\"\",\n","    #           \"Number of Processes\",\"Time(s)\",Title)\t\n"],"execution_count":0,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-4d24bc9b577c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0mTitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     drawLines([p.nbna, p.bna, p.bfr, p.bff],\"\",\n\u001b[0;32m--> 104\u001b[0;31m                \"Number of Processes\",\"Accuracy\",Title)\t\n\u001b[0m\u001b[1;32m    105\u001b[0m     \u001b[0;31m# drawLines([p.nbna, p.nbfr, p.nbpp, p.npff, p.bna, p.bfr, p.bff, p.bpp],\"\",\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;31m#           \"Number of Processes\",\"Time(s)\",Title)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-4d24bc9b577c>\u001b[0m in \u001b[0;36mdrawLines\u001b[0;34m(Lines, ImgOutName, XLabel, YLabel, Title)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mlinestyle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinestyles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         plt.plot(line.x_val_arr, line.y_val_arr, label=line.legend,\n\u001b[0;32m---> 49\u001b[0;31m                  linestyle=linestyle, linewidth=3)\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2761\u001b[0m     return gca().plot(\n\u001b[1;32m   2762\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m-> 2763\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1644\u001b[0m         \"\"\"\n\u001b[1;32m   1645\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1646\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1647\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1648\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    343\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (1,) and (0,)"]},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"HMhVSepfGht5","colab_type":"text"},"source":["# Accuracy\n","\n","### Occupation\n","PCA w n = 1 => 21.81% <br/> \n","PCA w n = 2 => 27.2% <br />\n","PCA w n = 3 => 27.53% <br />\n","PCA w n = 4 => 29.06% <br />\n","PCA w n = 5 => 29.5 % <br />\n","PCA w n = 10 => 32.28% <br />\n","PCA w n = 20 => 32.998% <br />\n","PCA w n = 30 => 33.29% <br />\n","PCA w n = 40 => 33.29% <br />\n","\n","### Workclass\n","PCA w n = 10 => 73.96% <br />\n","PCA w n = 20 => 74.3% <br />\n","PCA w n = 30 => 74.3% <br />\n","\n","### Education\n","PCA w n = 5 => 43.56% <br />\n","PCA w n = 10 -> 47.3% <br />\n","PCA w n = 20 => 48.82% <br />\n","PCA w n = 30 => 47.93% <br />\n","\n","### Marital Status \n","PCA w n = 5 => 67.48% <br />\n","PCA w n = 10 => 77.85% <br />\n","PCA w n = 20 => 79.33% <br />\n","PCA w n = 30 => 80.26% <br />\n","\n","### Relationship\n","PCA w n = 5 => 66.47 <br />\n","PCA w n = 10 => 70.86 <br />\n","PCA w n = 20 => 73.63 <br />\n","PCA w n = 30 => 74% <br />\n","\n","\n","### Race \n","PCA w n = 5 => 86.27% <br />\n","PCA w n= 10 => 86.98% <br />\n","PCA w n = 20 => 87.89% <br />\n","PCA w n = 30 => 87.79% <br />\n","\n","### Sex\n","PCA w n = 5 => 76.73 <br />\n","PCA w n = 10 => 82.15% <br />\n","PCA w n = 20 => 84. 31% <br />\n","PCA w n = 30 => 84.48% <br />\n","\n","### Native Country\n","\n","PCA w n = 5 => 91.54% <br />\n","Probably labeling most as American Citizens which is why it is so high <br />\n","\n","### Income\n","PCA w n = 5 => 81% <br />\n","PCA w n = 10 => 83.47% <br />"]},{"cell_type":"code","metadata":{"id":"pAhMUV5_Ght9","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}